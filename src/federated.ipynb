{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e175df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip install requests PIL torch torchvision numpy matplotlib glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e21aa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "NUM_CLIENTS = 3       \n",
    "ROUNDS = 5            \n",
    "LOCAL_EPOCHS = 3      \n",
    "LR = 0.001\n",
    "DATA_PATH = \"./data/auto_vi\"\n",
    "CATEGORY = \"pipe_staple\"  # Change here for 'pipe_clip' or 'engine_wiring'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39546b33",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- 2. Custom Dataset ---\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPipeStapleDataset\u001b[39;00m(Dataset):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, root_dir, category, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# --- 2. Custom Dataset ---\n",
    "class PipeStapleDataset(Dataset):\n",
    "    def __init__(self, root_dir, category, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = [] \n",
    "        \n",
    "        # Handle nested paths\n",
    "        base_path = os.path.join(root_dir, category, category)\n",
    "        if not os.path.exists(base_path):\n",
    "            base_path = os.path.join(root_dir, category)\n",
    "            \n",
    "        print(f\"--- Loading data from: {base_path} ---\")\n",
    "\n",
    "        for split in ['train', 'test']:\n",
    "            split_dir = os.path.join(base_path, split)\n",
    "            if not os.path.exists(split_dir): continue\n",
    "\n",
    "            for class_name in os.listdir(split_dir):\n",
    "                class_path = os.path.join(split_dir, class_name)\n",
    "                if not os.path.isdir(class_path): continue\n",
    "\n",
    "                # Label Logic: 0 = OK (Good), 1 = NOK (Anomaly/Missing/etc)\n",
    "                label = 0 if class_name.lower() == 'good' else 1\n",
    "                \n",
    "                image_files = glob.glob(os.path.join(class_path, \"*.png\"))\n",
    "                for img_p in image_files:\n",
    "                    self.samples.append((img_p, label))\n",
    "\n",
    "        self.targets = [s[1] for s in self.samples]\n",
    "        if len(self.samples) == 0: raise ValueError(\"No images found!\")\n",
    "        \n",
    "        # Stats\n",
    "        print(f\"Total images: {len(self.samples)} (OK: {self.targets.count(0)} / Anomaly: {self.targets.count(1)})\")\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c192fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Simple CNN Model ---\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 16 * 16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Data Loading & Splitting ---\n",
    "def load_data():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "    ])\n",
    "\n",
    "    dataset = PipeStapleDataset(DATA_PATH, CATEGORY, transform=transform)\n",
    "    \n",
    "    # Global Train/Test Split\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    \n",
    "    global_test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Non-IID Client Split (Sorted by label to create bias)\n",
    "    train_indices = np.array(train_dataset.indices)\n",
    "    train_targets = np.array(dataset.targets)[train_indices]\n",
    "    \n",
    "    sorted_indices = np.argsort(train_targets)\n",
    "    client_shards = np.array_split(sorted_indices, NUM_CLIENTS)\n",
    "    \n",
    "    client_loaders = []\n",
    "    print(\"\\n--- Client Distribution (Non-IID) ---\")\n",
    "    for i, shard in enumerate(client_shards):\n",
    "        subset = Subset(dataset, train_indices[shard])\n",
    "        client_loaders.append(DataLoader(subset, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        print(f\"Client {i+1}: {len(subset)} images assigned.\")\n",
    "        \n",
    "    return client_loaders, global_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. FL Functions & Evaluation ---\n",
    "def local_train(model, loader, epochs):\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # NOTE: Si le mod√®le triche (0 anomalies d√©tect√©es), remplacez la ligne ci-dessous\n",
    "    # par : criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 5.0]).to(device))\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model.state_dict()\n",
    "\n",
    "def federated_average(global_w, local_ws):\n",
    "    avg_w = copy.deepcopy(global_w)\n",
    "    for key in avg_w.keys():\n",
    "        avg_w[key] = torch.stack([w[key] for w in local_ws]).mean(dim=0)\n",
    "    return avg_w\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    \"\"\"Full evaluation with sklearn metrics\"\"\"\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    report = classification_report(y_true, y_pred, target_names=['OK', 'Anomaly'], output_dict=True, zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    accuracy = report['accuracy'] * 100\n",
    "    f1_anomaly = report['Anomaly']['f1-score']\n",
    "    \n",
    "    return accuracy, f1_anomaly, cm, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2537f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Main Execution ---\n",
    "print(f\"--- üöÄ Starting Federated Learning on {CATEGORY} ---\")\n",
    "\n",
    "try:\n",
    "    client_loaders, test_loader = load_data()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    # Stop execution in notebook if data fails\n",
    "    raise e\n",
    "\n",
    "global_model = SimpleCNN().to(device)\n",
    "global_weights = global_model.state_dict()\n",
    "\n",
    "# History for plotting\n",
    "history_acc = []\n",
    "history_f1 = []\n",
    "\n",
    "print(\"\\n--- Start of Federated Training ---\")\n",
    "for r in range(ROUNDS):\n",
    "    print(f\"\\nüì° --- Round {r+1}/{ROUNDS} ---\")\n",
    "    local_weights = []\n",
    "    \n",
    "    # 1. Local Client Training\n",
    "    for i in range(NUM_CLIENTS):\n",
    "        client_model = SimpleCNN().to(device)\n",
    "        client_model.load_state_dict(global_weights)\n",
    "        w_client = local_train(client_model, client_loaders[i], epochs=LOCAL_EPOCHS)\n",
    "        local_weights.append(w_client)\n",
    "    \n",
    "    # 2. Server Aggregation (FedAvg)\n",
    "    global_weights = federated_average(global_weights, local_weights)\n",
    "    global_model.load_state_dict(global_weights)\n",
    "    \n",
    "    # 3. Global Evaluation\n",
    "    acc, f1, cm, _ = evaluate(global_model, test_loader)\n",
    "    history_acc.append(acc)\n",
    "    history_f1.append(f1)\n",
    "    \n",
    "    # Console Display\n",
    "    print(f\" -> Global Accuracy: {acc:.2f}%\")\n",
    "    print(f\" -> Anomaly F1-Score: {f1:.2f}\")\n",
    "    \n",
    "    if len(cm) == 2:\n",
    "        missed_defects = cm[1][0]\n",
    "        print(f\" ‚ö†Ô∏è  MISSED Defects (False Negatives): {missed_defects}\")\n",
    "    else:\n",
    "        print(f\" Matrix:\\n{cm}\")\n",
    "\n",
    "print(\"\\n‚úÖ Simulation Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e949e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Final Results & Plotting ---\n",
    "\n",
    "# Save Model\n",
    "model_filename = f\"model_{CATEGORY}.pth\"\n",
    "torch.save(global_model.state_dict(), model_filename)\n",
    "print(f\"üíæ Model saved as: {model_filename}\")\n",
    "\n",
    "# Save and Show Confusion Matrix\n",
    "acc, f1, cm, _ = evaluate(global_model, test_loader)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['OK', 'Anomaly'], yticklabels=['OK', 'Anomaly'])\n",
    "plt.title(f'Final Confusion Matrix - {CATEGORY}')\n",
    "plt.ylabel('True Class')\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.savefig(f\"confusion_matrix_{CATEGORY}.png\")\n",
    "plt.show() # Added plt.show() for notebook\n",
    "\n",
    "# Save and Show Learning Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, ROUNDS + 1), history_acc, 'b-o', label='Global Accuracy')\n",
    "plt.plot(range(1, ROUNDS + 1), [x*100 for x in history_f1], 'r--s', label='Anomaly F1-Score')\n",
    "plt.title(f'FedAvg Performance - {CATEGORY}')\n",
    "plt.xlabel('Communication Rounds')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"metrics_{CATEGORY}.png\")\n",
    "plt.show() # Added plt.show() for notebook\n",
    "print(f\"üìà Charts saved as 'metrics_{CATEGORY}.png'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
