{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12345223,"sourceType":"datasetVersion","datasetId":7782615}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nfrom PIL import Image\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom torchvision import transforms, models\n\n# --- CONFIGURATION ---\nBATCH_SIZE = 64\nIMG_SIZE = 128\nLEARNING_RATE = 1e-4\nEPOCHS = 15\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(f\"âš™ï¸ Configuration : {DEVICE} | Batch: {BATCH_SIZE} | Img: {IMG_SIZE}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch\n\n# --- CONFIGURATION ---\n# Change this path to your local folder containing the subfolders\nDATA_ROOT = \"/kaggle/input/autovi-dataset-version-1-0-0/AUTOVI Dataset Version 1.0.0/10459003\" \n\ntrain_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\nclass UniversalAutoViDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_paths = []\n        self.labels = []       \n        self.part_names = []   \n        self.stratify_labels = [] \n        \n        seen_filenames = set()\n\n        for root, dirs, files in os.walk(root_dir):\n            png_files = [f for f in files if f.lower().endswith('.png')]\n            if not png_files: continue\n            \n            path_parts = root.split(os.sep)\n            # Detect part name from directory structure\n            part_name = \"unknown\"\n            if 'train' in path_parts:\n                part_name = path_parts[path_parts.index('train') - 1]\n            elif 'test' in path_parts:\n                part_name = path_parts[path_parts.index('test') - 1]\n            else:\n                continue \n\n            if part_name in ['ground_truth', 'images']: continue\n\n            for file in png_files:\n                unique_id = f\"{part_name}/{file}\"\n                if unique_id in seen_filenames: continue\n                seen_filenames.add(unique_id)\n\n                self.image_paths.append(os.path.join(root, file))\n                label = 0 if 'good' in path_parts else 1\n                self.labels.append(label)\n                self.part_names.append(part_name)\n                self.stratify_labels.append(f\"{part_name}_{label}\")\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_paths[idx]).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, torch.tensor(self.labels[idx], dtype=torch.long), self.part_names[idx]\n\n# --- INITIALIZATION ---\ntry:\n    full_dataset = UniversalAutoViDataset(DATA_ROOT, transform=None)\n\n    train_idx, test_idx = train_test_split(\n        list(range(len(full_dataset))),\n        test_size=0.2,\n        stratify=full_dataset.stratify_labels, \n        random_state=42\n    )\n\n    train_loader = DataLoader(\n        UniversalAutoViDataset(DATA_ROOT, transform=train_transform), \n        batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(train_idx)\n    )\n    test_loader = DataLoader(\n        UniversalAutoViDataset(DATA_ROOT, transform=test_transform), \n        batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(test_idx)\n    )\n    \n    print(f\"Data loaded: {len(train_idx)} train, {len(test_idx)} test images.\")\nexcept Exception as e:\n    print(f\"Error: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ExpertResNet(nn.Module):\n    def __init__(self):\n        super(ExpertResNet, self).__init__()\n        self.net = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n        \n        num_features = self.net.fc.in_features\n        self.net.fc = nn.Linear(num_features, 2)\n        \n    def forward(self, x):\n        return self.net(x)\n    \n    def get_last_conv_layer(self):\n        return self.net.layer4[-1]\n\nmodel = ExpertResNet().to(DEVICE)\nprint(\"âœ… ModÃ¨le ResNet18 chargÃ©.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_labels = [full_dataset.labels[i] for i in train_idx]\nn_good = train_labels.count(0)\nn_defect = train_labels.count(1)\nweight = n_good / n_defect if n_defect > 0 else 1.0\n\nprint(f\"âš–ï¸ Balance Train -> Good: {n_good}, Defect: {n_defect} (Poids: {weight:.2f})\")\nclass_weights = torch.tensor([1.0, weight]).to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n\ndef train_loop():\n    train_losses = []\n    \n    for epoch in range(EPOCHS):\n        model.train()\n        running_loss = 0.0\n        \n        for images, labels, _ in train_loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            \n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for images, labels, _ in test_loader:\n                images, labels = images.to(DEVICE), labels.to(DEVICE)\n                outputs = model(images)\n                val_loss += criterion(outputs, labels).item()\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n        \n        avg_train_loss = running_loss / len(train_loader)\n        avg_val_loss = val_loss / len(test_loader)\n        acc = 100 * correct / total\n        train_losses.append(avg_train_loss)\n        \n        lr = optimizer.param_groups[0]['lr']\n        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Acc: {acc:.2f}% | LR: {lr:.1e}\")\n        \n        scheduler.step(avg_val_loss)\n        \n    return train_losses\n\nhistory = train_loop()\ntorch.save(model.state_dict(), \"resnet_autovi_final.pth\")\nprint(\"ðŸ’¾ ModÃ¨le sauvegardÃ©.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_by_part(model, loader):\n    model.eval()\n    \n    y_true = []\n    y_pred = []\n    y_parts = []\n    \n    with torch.no_grad():\n        for images, labels, parts in loader:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            \n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(predicted.cpu().numpy())\n            y_parts.extend(parts)\n            \n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(6, 5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=['Good', 'Defect'], yticklabels=['Good', 'Defect'])\n    plt.title('Matrice de Confusion Globale')\n    plt.show()\n    \n    print(\"\\n--- ðŸ“Š PrÃ©cision par Type de PiÃ¨ce ---\")\n    print(f\"{'PiÃ¨ce':<20} | {'Total':<6} | {'PrÃ©cision':<8}\")\n    print(\"-\" * 45)\n    \n    unique_parts = sorted(list(set(y_parts)))\n    for part in unique_parts:\n        indices = [i for i, p in enumerate(y_parts) if p == part]\n        \n        part_true = [y_true[i] for i in indices]\n        part_pred = [y_pred[i] for i in indices]\n        \n        if len(indices) > 0:\n            correct = sum([1 for t, p in zip(part_true, part_pred) if t == p])\n            acc = 100 * correct / len(indices)\n            print(f\"{part:<20} | {len(indices):<6} | {acc:.2f}%\")\n\nprint(\"ðŸ” Analyse dÃ©taillÃ©e...\")\nevaluate_by_part(model, test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- CLASSE GRAD-CAM ---\nclass GradCAM:\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n        self.gradients = None\n        self.activations = None\n        self.target_layer.register_forward_hook(self.save_activation)\n        self.target_layer.register_full_backward_hook(self.save_gradient)\n\n    def save_activation(self, module, input, output):\n        self.activations = output\n\n    def save_gradient(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0]\n\n    def __call__(self, x, class_idx=None):\n        output = self.model(x)\n        if class_idx is None:\n            class_idx = torch.argmax(output)\n            \n        self.model.zero_grad()\n        score = output[0, class_idx]\n        score.backward()\n        \n        gradients = self.gradients[0]\n        pooled_gradients = torch.mean(gradients, dim=[1, 2])\n        activations = self.activations[0]\n        \n        for i in range(activations.shape[0]):\n            activations[i, :, :] *= pooled_gradients[i]\n            \n        heatmap = torch.mean(activations, dim=0).cpu().detach().numpy()\n        heatmap = np.maximum(heatmap, 0)\n        if np.max(heatmap) != 0:\n            heatmap /= np.max(heatmap)\n        return heatmap\n\ndef show_cam(model, dataset, idx):\n\n    img_pil, lbl, part_name = dataset[idx]\n    \n    input_tensor = test_transform(img_pil).unsqueeze(0).to(DEVICE)\n    \n    target_layer = model.get_last_conv_layer()\n    grad_cam = GradCAM(model, target_layer)\n    \n    heatmap = grad_cam(input_tensor, class_idx=1)\n    \n    plt.figure(figsize=(10, 4))\n    \n    img_disp = np.array(img_pil) \n    \n    plt.subplot(1, 2, 1)\n    plt.imshow(img_disp)\n    plt.title(f\"PiÃ¨ce: {part_name}\\nLabel: {'Defect' if lbl==1 else 'Good'}\")\n    plt.axis('off')\n    \n    plt.subplot(1, 2, 2)\n    heatmap = cv2.resize(heatmap, (img_disp.shape[1], img_disp.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    \n    superimposed = cv2.addWeighted(img_disp, 0.6, heatmap, 0.4, 0)\n    \n    plt.imshow(superimposed)\n    plt.title(\"Grad-CAM Focus\")\n    plt.axis('off')\n    plt.show()\n\n# --- TEST ---\nprint(\"ðŸ“¸ Visualisation d'un dÃ©faut alÃ©atoire...\")\ndefect_indices = [i for i, x in enumerate(full_dataset.labels) if x == 1]\n\nif defect_indices:\n    import random\n    for _ in range(3):\n        idx = random.choice(defect_indices)\n        show_cam(model, full_dataset, idx)\nelse:\n    print(\"Aucun dÃ©faut trouvÃ© dans le dataset.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nplt.plot(history, label='Training Loss')\nplt.title('Courbe d\\'apprentissage (ResNet18)')\nplt.xlabel('Ã‰poques')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}